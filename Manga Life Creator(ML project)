#THIS IS THE FACE DETECTION PART OF MY PROGRAM

import cv2
import sys
import os.path
#lbp cascade
def detect(filename, cascade_file = "../lbpcascade_animeface.xml"):
    if not os.path.isfile(cascade_file):
        raise RuntimeError("%s: not found" % cascade_file)

    cascade = cv2.CascadeClassifier(cascade_file)
    image = cv2.imread(filename, cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  #applying grayscale to increase processing speed
    gray = cv2.equalizeHist(gray)
    
    faces = cascade.detectMultiScale(gray,
                                     # detector options
                                     scaleFactor = 1.1,
                                     minNeighbors = 5,
                                     minSize = (24, 24))
    for (x, y, w, h) in faces:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)

    cv2.imshow("AnimeFaceDetect", image)
    cv2.waitKey(0)
    cv2.imwrite("out.png", image)

if len(sys.argv) != 2:
    sys.stderr.write("usage: detect.py <filename>\n")
    sys.exit(-1)
    
detect(sys.argv[1])


#THIS IS THE TEXT DETECTION AND READER PART OF PROGRAM (MANGA TEXT SEGMENTATION) (Refer to largecats.github.io site for article named OCR with comics)(Using Tesseract)

#THE INPUT TO THIS PART OF PROGRAM  WILL BE 1 MANGA PANEL PER INSTANCE, SO THAT THE PROGRAM READS ALL THE TEXT FROM TEXT BUBBLES AND STORES THE EXTRACTED TEXT AND SAVES IT SOMEWHERE ELSE

 #OCR is the conversion of images of text into machine-encoded text. We will use it to extract text from the comicsâ€™ speech bubbles. 
 #We can then store the text along with the paths of the corresponding comic pages to make a text-path dictionary. 
 # In this way, when we need a comic page that contains a certain word,
 #  we can simply search for the word in this dictionary and look up the path of the comic page that contains it


import cv2
import enchant
import numpy 
import os
import pytesseract
import re
import csv
from matplotlib import pyplot as pt

 #find all speech bubbles in the given comic page and return a list of cropped speech bubbles(with possible false positives)

 def findSpeechBubbles(imagepath,method='simple'):
     #read image
     image=cv2.imread(imagepath)

     imageGray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY) #Grayscale conversion for ease 
     #filter noise
     imageGrayBlur=cv2.GaussianBlur(imageGray,(3,3),0)
     
     if method!='simple'
     #recognizes more complex shape bubbles other than rectangle or circle
       imageGrayBlurCanny = cv2.Canny(imageGrayBlur,50,500)
        binary = cv2.threshold(imageGrayBlurCanny,235,255,cv2.THRESH_BINARY)[1]
    else:
        # recognizes only rectangular bubbles
        binary = cv2.threshold(imageGrayBlur,235,255,cv2.THRESH_BINARY)[1]

        #finding contours
        contours=cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)[1]
        # get the list of cropped speech bubbles
    croppedImageList = []
    for contour in contours:
        rect = cv2.boundingRect(contour)
        [x, y, w, h] = rect
        # filter out speech bubble candidates with unreasonable size
        if w < 500 and w > 60 and h < 500 and h > 25:
            croppedImage = image[y:y+h, x:x+w]
            croppedImageList.append(croppedImage)

    return croppedImageList

#Somehow, images cropped this way (via the image[y:y+h, x:x+w] syntax) are not as good for OCR as images cropped using external programs, such as QQ

# apply the ocr engine to the given image and return the recognized script where illegitimate characters are filtered out
def tesseract(image):
    script = pytesseract.image_to_string(image, lang = 'eng')
    for char in script:
        if char not in ' -QWERTYUIOPASDFGHJKLZXCVBNMqwertyuiopasdfghjklzxcvbnm,.?!1234567890"":;\'':
            script = script.replace(char,'')
    
    return script

    # loop through each file in the given directory, not including zip files
def looper(rootDir):
    fileNameList = []
    filePathList = []
    for subDir, dirs, files in os.walk(rootDir):
        for file in files:
            fileInfo = file.split('.')
            fileName, fileExten = fileInfo[0], fileInfo[-1]
            filePath = os.path.join(subDir, file)
            if fileExten == 'jpg' or fileExten == 'png' or fileExten == '.bmp':
            # if fileExten != 'zip':
                if fileName not in fileNameList:
                    fileNameList.append(fileName)
                    filePathList.append(filePath)

    return filePathList

# append image path and script to the output csv file
def write_script_to_csv(imagePath, script, outputFilePath):
    with open(outputFilePath, 'a', encoding = "utf-8", newline = "") as f:
        writer = csv.writer(f)
        newRow = [imagePath, script]
        writer.writerow(newRow)

        # initialize output file
with open(outputFilePath, 'w',newline = "") as f:
    writer = csv.writer(f)
    writer.writerow(['filePath', 'script'])

# for each image in the given directory, process each speech bubble found and feed it to the ocr engine
for imagePath in looper(rootDir):
    print(imagePath)
    # find speech bubbles in each image
    try:
        croppedImageList = findSpeechBubbles(imagePath, method = 'simple')
    except:
        continue
    scriptList = []
    for croppedImage in croppedImageList:
        # enlarge
        croppedImage = cv2.resize(croppedImage, (0,0), fx = 2, fy = 2)
        # denoise
        croppedImage = denoise(croppedImage, 2)
        kernel = np.ones((1, 1), np.uint8)
        croppedImage = cv2.dilate(croppedImage, kernel, iterations = 50)
        croppedImage = cv2.erode(croppedImage, kernel, iterations = 50)

        # turn gray
        croppedImageGray = cv2.cvtColor(croppedImage, cv2.COLOR_BGR2GRAY)
        # Gaussian filter
        croppedImageGrayBlur = cv2.GaussianBlur(croppedImageGray,(5,5),0)
        # edge detection
        croppedImageGrayBlurLaplacian = cv2.Laplacian(croppedImageGrayBlur,cv2.CV_64F)
        # adjust contrast and brightness
        croppedImageGrayBlurLaplacian = np.uint8(np.clip((10 * croppedImageGrayBlurLaplacian + 10), 0, 255))

        # pass cropped image to the ocr engine
        script = tesseract(croppedImageGrayBlurLaplacian)
        if script != '' and script not in scriptList:
            scriptList.append(script)
            print(script)
            # append image path and script to the output csv file
            write_script_to_csv(imagePath, script, outputFilePath)




#THIS IS THE TEXT TO EMOTION FILLED(BY READING FACIAL EXPRESSIONS) AI GENERATED VOICE PART OF THE PROGRAM





#THIS IS THE IMAGE GENERATION PART OF PROGRAM(USING GANs)



#AI draws manga and creates new manga panels(by taking keywords as input for creating new story material, and then filling it in text bubbles in manga) Part of program



#Manga colorization
